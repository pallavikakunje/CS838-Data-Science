{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this jupyter notebook we are performing entity matching using two tables named as \"google\" and \"apple\". These tables contains attributes related to games available on playstore and appstore. We are trying to match games present in these tables. We want to have a precision of atleast 90% and recall as high as possible.\n",
    "\n",
    "First, we need to import py_entitymatching package and other libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 2.7.13 |Anaconda 4.3.0 (32-bit)| (default, Dec 20 2016, 23:08:16) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "pandas version: 0.19.2\n",
      "magellan version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/pradap/Documents/Research/Python-Package/anhaid/py_entitymatching/')\n",
    "\n",
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print('python version: ' + sys.version )\n",
    "print('pandas version: ' + pd.__version__ )\n",
    "print('magellan version: ' + em.__version__ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching two tables typically consists of the following three steps:\n",
    "\n",
    "<b>1. Reading the input tables</b>\n",
    "\n",
    "<b>2. Blocking the input tables to get a candidate set</b>\n",
    "\n",
    "<b>3. Matching the tuple pairs in the candidate set</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the input tables. We need to provide the path where we have stored the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaurav/DS/stage3/csv_data/playstore_formatted.csv\n",
      "/home/gaurav/DS/stage3/csv_data/appstore_formatted.csv\n"
     ]
    }
   ],
   "source": [
    "#Get the paths\n",
    "path_google = \"/home/gaurav/DS/stage3/csv_data/\" + \"playstore_formatted.csv\"\n",
    "path_apple = \"/home/gaurav/DS/stage3/csv_data/\" + \"appstore_formatted.csv\"\n",
    "\n",
    "print path_google\n",
    "print path_apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuples in table \"google:\" 3789\n",
      "Number of tuples in table \"apple:\" 3697\n",
      "Number of tuples in \"google\" X \"apple\" (i.e the cartesian product): 14007933\n"
     ]
    }
   ],
   "source": [
    "# Load csv files as dataframes and set the key attribute in the dataframe\n",
    "google = em.read_csv_metadata(path_google, key='ID')\n",
    "apple = em.read_csv_metadata(path_apple, key='ID')\n",
    "\n",
    "print('Number of tuples in table \"google:\" ' + str(len(google)))\n",
    "print('Number of tuples in table \"apple:\" ' + str(len(apple)))\n",
    "print('Number of tuples in \"google\" X \"apple\" (i.e the cartesian product): ' + str(len(google)*len(apple)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>developer</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>Solitaire - Klondike</td>\n",
       "      <td>Card</td>\n",
       "      <td>Kiwi Solitaire</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>slither.io</td>\n",
       "      <td>Action</td>\n",
       "      <td>Lowtech Studios</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                  name category        developer rating\n",
       "0  a1  Solitaire - Klondike     Card   Kiwi Solitaire    4.3\n",
       "1  a2            slither.io   Action  Lowtech Studios    4.3"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing few rows\n",
    "google.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>developer</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1</td>\n",
       "      <td>Candy Crush Saga</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>King</td>\n",
       "      <td>4.70807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2</td>\n",
       "      <td>Super Mario Run</td>\n",
       "      <td>Action</td>\n",
       "      <td>Nintendo Co., Ltd.</td>\n",
       "      <td>2.97468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              name       category           developer   rating\n",
       "0  b1  Candy Crush Saga  Entertainment                King  4.70807\n",
       "1  b2   Super Mario Run         Action  Nintendo Co., Ltd.  2.97468"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ID', 'ID')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the keys of the input tables\n",
    "em.get_key(google), em.get_key(apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block Tables To Get Candidate Set\n",
    "\n",
    "Before we do the matching, we would like to remove the obviously non-matching tuple pairs from the input tables. This would reduce the number of tuple pairs considered for matching. py_entitymatching provides four different blockers: (1) attribute equivalence, (2) overlap, (3) rule-based, and (4) black-box. The user can mix and match these blockers to form a blocking sequence applied to input tables.\n",
    "\n",
    "For the matching problem at hand, we know that games with no overlap between name will not match. Also, there should be overlap between developer name as well. So we decide to apply blocking over game name and developer name:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blocking plan\n",
    "\n",
    "# google, apple -- Overlap blocker [name] --------------------|---> candidate set 1\n",
    "# candidate set 1 -- Overlap blocker [developer] -------------|---> candidate set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00 | ETA: 00:00:01 | ETA: 00:00:01 | ETA: 00:00:01 | ETA: 00:00:01 | ETA: 00:00:01 | ETA: 00:00:01 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00 | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4307"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create overlap blocker\n",
    "ob = em.OverlapBlocker()\n",
    "\n",
    "# Block tables using 'name' attribute \n",
    "cand_1 = ob.block_tables(google, apple, 'name', 'name', \n",
    "                    l_output_attrs=['name', 'category', 'developer', 'rating'], \n",
    "                    r_output_attrs=['name', 'category', 'developer', 'rating'],\n",
    "                    overlap_size=2, show_progress=False\n",
    "                    )\n",
    "\n",
    "# Again applying blocking using 'developer' attribute\n",
    "cand_2 = ob.block_candset(cand_1, 'developer', 'developer', word_level=True, overlap_size=1, show_progress=False)\n",
    "\n",
    "len(cand_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match tuple pairs in candidate set\n",
    "\n",
    "In this step, we would want to match the tuple pairs in the candidate set. Specifically, we use learning-based method for matching purposes. This typically involves the following four steps:\n",
    "\n",
    "    1. Sampling and labeling the candidate set\n",
    "    2. Splitting the labeled data into development and evaluation set\n",
    "    3. Selecting the best learning based matcher using the development set\n",
    "    4. Evaluating the selected matcher using the evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling the candidate set\n",
    "\n",
    "Our blocking step efficiently eliminated most of the obvious non matching tuple pairs. Hence we don't need to further sample the data. Complete candidate set obtained after blocking is used for labeling.\n",
    "\n",
    "For labeling, we are converting candidate set back to .csv file and labeling the tuples manually. We are adding a column named 'label' and enter 0 for mismatch and 1 for match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting to .csv file\n",
    "cand_2.to_csv('cand_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4307"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading back the file after adding the labels\n",
    "read_back = em.read_csv_metadata('cand_2.csv', \n",
    "                         key='_id',\n",
    "                         ltable=google, rtable=apple, \n",
    "                         fk_ltable='ltable_ID', fk_rtable='rtable_ID')\n",
    "\n",
    "len(read_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the labeled data into development and evaluation set\n",
    "\n",
    "In this step, we split the labeled data into two sets: development (I) and evaluation (J). Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data in read_back into development set (I) and evaluation set (J)\n",
    "IJ = em.split_train_test(read_back, train_proportion=0.7, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best learning-based matcher\n",
    "\n",
    "Selecting the best learning-based matcher typically involves the following steps:\n",
    "\n",
    "    1. Creating a set of learning-based matchers\n",
    "    2. Creating features\n",
    "    3. Converting the development set into feature vectors\n",
    "    4. Selecting the best learning-based matcher using k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a set of learning-based matchers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features\n",
    "Next, we need to create a set of features for the development set. py_entitymatching provides a way to automatically generate features based on the attributes in the input tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate features\n",
    "feature_table = em.get_features_for_matching(google, apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the development set to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=feature_table, \n",
    "                            attrs_after='label',\n",
    "                            show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_ID</th>\n",
       "      <th>rtable_ID</th>\n",
       "      <th>ID_ID_lev_dist</th>\n",
       "      <th>ID_ID_lev_sim</th>\n",
       "      <th>ID_ID_jar</th>\n",
       "      <th>ID_ID_jwn</th>\n",
       "      <th>ID_ID_exm</th>\n",
       "      <th>ID_ID_jac_qgm_3_qgm_3</th>\n",
       "      <th>name_name_jac_qgm_3_qgm_3</th>\n",
       "      <th>...</th>\n",
       "      <th>category_category_sw</th>\n",
       "      <th>developer_developer_jac_qgm_3_qgm_3</th>\n",
       "      <th>developer_developer_cos_dlm_dc0_dlm_dc0</th>\n",
       "      <th>developer_developer_jac_dlm_dc0_dlm_dc0</th>\n",
       "      <th>developer_developer_mel</th>\n",
       "      <th>developer_developer_lev_dist</th>\n",
       "      <th>developer_developer_lev_sim</th>\n",
       "      <th>developer_developer_nmw</th>\n",
       "      <th>developer_developer_sw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>30692</td>\n",
       "      <td>a2306</td>\n",
       "      <td>b2285</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>11078</td>\n",
       "      <td>a1501</td>\n",
       "      <td>b1178</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>37880</td>\n",
       "      <td>a734</td>\n",
       "      <td>b3118</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.312865</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id ltable_ID rtable_ID  ID_ID_lev_dist  ID_ID_lev_sim  ID_ID_jar  \\\n",
       "3018  30692     a2306     b2285               4            0.2   0.466667   \n",
       "1364  11078     a1501     b1178               4            0.2   0.466667   \n",
       "3817  37880      a734     b3118               5            0.0   0.483333   \n",
       "\n",
       "      ID_ID_jwn  ID_ID_exm  ID_ID_jac_qgm_3_qgm_3  name_name_jac_qgm_3_qgm_3  \\\n",
       "3018   0.466667          0                    0.0                   0.243590   \n",
       "1364   0.466667          0                    0.0                   0.100000   \n",
       "3817   0.483333          0                    0.0                   0.025641   \n",
       "\n",
       "      ...    category_category_sw  developer_developer_jac_qgm_3_qgm_3  \\\n",
       "3018  ...                     2.0                             0.063492   \n",
       "1364  ...                     1.0                             0.137931   \n",
       "3817  ...                     1.0                             0.160000   \n",
       "\n",
       "      developer_developer_cos_dlm_dc0_dlm_dc0  \\\n",
       "3018                                 0.192450   \n",
       "1364                                 0.353553   \n",
       "3817                                 0.353553   \n",
       "\n",
       "      developer_developer_jac_dlm_dc0_dlm_dc0  developer_developer_mel  \\\n",
       "3018                                 0.090909                 0.504762   \n",
       "1364                                 0.200000                 0.473430   \n",
       "3817                                 0.200000                 0.312865   \n",
       "\n",
       "      developer_developer_lev_dist  developer_developer_lev_sim  \\\n",
       "3018                          44.0                     0.120000   \n",
       "1364                          19.0                     0.173913   \n",
       "3817                          15.0                     0.210526   \n",
       "\n",
       "      developer_developer_nmw  developer_developer_sw  label  \n",
       "3018                    -30.0                     6.0      0  \n",
       "1364                    -13.0                     4.0      0  \n",
       "3817                     -9.0                     4.0      0  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "H.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best matcher using cross-validation\n",
    "\n",
    "Now, we select the best matcher using k-fold cross-validation. We use five fold cross validation and use 'precision', 'recall' and 'f1' metric to select the best matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0xa881b8cc&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0xa83c8a8c&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0xa83c8acc&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.951519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0xa83c8aac&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.961284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0xa83c8a6c&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.936485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0xa83c8aec&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.479868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                        Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0xa881b8cc>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0xa83c8a8c>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0xa83c8acc>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0xa83c8aac>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0xa83c8a6c>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0xa83c8aec>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.979592  0.972603  0.967213  0.945205  1.000000    0.972923  \n",
       "1          5  1.000000  1.000000  1.000000  0.985294  1.000000    0.997059  \n",
       "2          5  0.895833  1.000000  0.962264  0.981132  0.918367    0.951519  \n",
       "3          5  0.903846  0.985294  1.000000  0.985075  0.932203    0.961284  \n",
       "4          5  0.886792  0.957746  0.904762  0.984848  0.948276    0.936485  \n",
       "5          5  0.405172  0.511278  0.468750  0.485294  0.528846    0.479868  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the best ML matcher using CV\n",
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "        k=5,\n",
    "        target_attr='label', metric='precision', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0xa881b8cc&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.978388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0xa83c8a8c&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.963443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0xa83c8acc&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.809406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0xa83c8aac&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.934971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0xa83c8a6c&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.931717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0xa83c8aec&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.944098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                        Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0xa881b8cc>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0xa83c8a8c>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0xa83c8acc>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0xa83c8aac>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0xa83c8a6c>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0xa83c8aec>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  1.000000  0.986111  0.936508  0.985714  0.983607    0.978388  \n",
       "1          5  1.000000  0.972222  0.920635  0.957143  0.967213    0.963443  \n",
       "2          5  0.895833  0.861111  0.809524  0.742857  0.737705    0.809406  \n",
       "3          5  0.979167  0.930556  0.920635  0.942857  0.901639    0.934971  \n",
       "4          5  0.979167  0.944444  0.904762  0.928571  0.901639    0.931717  \n",
       "5          5  0.979167  0.944444  0.952381  0.942857  0.901639    0.944098  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "        k=5,\n",
    "        target_attr='label', metric='recall', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0xa881b8cc&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.975477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0xa83c8a8c&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.979788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0xa83c8acc&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.872845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0xa83c8aac&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.947198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0xa83c8a6c&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.933351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0xa83c8aec&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.663415</td>\n",
       "      <td>0.628272</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.634460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5    NaiveBayes   \n",
       "\n",
       "                                                                        Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0xa881b8cc>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0xa83c8a8c>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0xa83c8acc>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0xa83c8aac>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0xa83c8a6c>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0xa83c8aec>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.989691  0.979310  0.951613  0.965035  0.991736    0.975477  \n",
       "1          5  1.000000  0.985915  0.958678  0.971014  0.983333    0.979788  \n",
       "2          5  0.895833  0.925373  0.879310  0.845528  0.818182    0.872845  \n",
       "3          5  0.940000  0.957143  0.958678  0.963504  0.916667    0.947198  \n",
       "4          5  0.930693  0.951049  0.904762  0.955882  0.924370    0.933351  \n",
       "5          5  0.573171  0.663415  0.628272  0.640777  0.666667    0.634460  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "        k=5,\n",
    "        target_attr='label', metric='f1', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the best matcher (RF) is getting us the best precision and f1. Recall is also high and is only slightly less than that for DecisionTree. So, we select <b>RF matcher</b> and now we can proceed on to evaluating the best matcher on the unseen data (the evaluation set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the matching output\n",
    "\n",
    "Evaluating the matching outputs for the evaluation set typically involves the following four steps:\n",
    "\n",
    "    1. Converting the evaluation set to feature vectors\n",
    "    2. Training matcher using the feature vectors extracted from the development set\n",
    "    3. Predicting the evaluation set using the trained matcher\n",
    "    4. Evaluating the predicted matches\n",
    "    \n",
    "\n",
    "### Converting the evaluation set to feature vectors\n",
    "\n",
    "As before, we convert to the feature vectors (using the feature table and the evaluation set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert J into a set of feature vectors using feature table\n",
    "L = em.extract_feature_vecs(J, feature_table=feature_table,\n",
    "                            attrs_after='label', show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training matcher, predicting the evaluation set and evaluating predicted matches for each matcher\n",
    "\n",
    "We train the matchers using all of the feature vectors from the development set.\n",
    "\n",
    "We predict the matches for the evaluation set (using the feature vectors extracted from it).\n",
    "\n",
    "Finally, we evaluate the accuracy of predicted outputs.\n",
    "\n",
    "#### 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 98.87% (175/177)\n",
      "Recall : 98.31% (175/178)\n",
      "F1 : 98.59%\n",
      "False positives : 2 (out of 177 positive predictions)\n",
      "False negatives : 3 (out of 1116 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "dt.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "# Predict on L \n",
    "predictions = dt.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 99.43% (175/176)\n",
      "Recall : 98.31% (175/178)\n",
      "F1 : 98.87%\n",
      "False positives : 1 (out of 176 positive predictions)\n",
      "False negatives : 3 (out of 1117 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "rf.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 96.77% (150/155)\n",
      "Recall : 84.27% (150/178)\n",
      "F1 : 90.09%\n",
      "False positives : 5 (out of 155 positive predictions)\n",
      "False negatives : 28 (out of 1138 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "svm.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "# Predict on L \n",
    "predictions = svm.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 97.08% (166/171)\n",
      "Recall : 93.26% (166/178)\n",
      "F1 : 95.13%\n",
      "False positives : 5 (out of 171 positive predictions)\n",
      "False negatives : 12 (out of 1122 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "ln.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "# Predict on L \n",
    "predictions = ln.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 91.76% (167/182)\n",
      "Recall : 93.82% (167/178)\n",
      "F1 : 92.78%\n",
      "False positives : 15 (out of 182 positive predictions)\n",
      "False negatives : 11 (out of 1111 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "lg.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 58.68% (169/288)\n",
      "Recall : 94.94% (169/178)\n",
      "F1 : 72.53%\n",
      "False positives : 119 (out of 288 positive predictions)\n",
      "False negatives : 9 (out of 1005 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from I \n",
    "nb.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'],\n",
    "       target_attr='label')\n",
    "\n",
    "# Predict on L \n",
    "predictions = nb.predict(table=L, exclude_attrs=['_id', 'ltable_ID', 'rtable_ID', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best matcher\n",
    "\n",
    "RF matcher performed best in the evaluation set as well. Here are the statistics:\n",
    "\n",
    "Precision : 99.43% (175/176)\n",
    "\n",
    "Recall : 98.31% (175/178)\n",
    "\n",
    "F1 : 98.87%\n",
    "\n",
    "False positives : 1 (out of 176 positive predictions)\n",
    "\n",
    "False negatives : 3 (out of 1117 negative predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
